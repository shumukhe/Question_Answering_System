# ğŸ¤– Conversational QA Bot (CoQA-Based)

This is a conversational Question Answering bot fine-tuned on the [CoQA dataset](https://stanfordnlp.github.io/coqa/). It uses a custom-trained T5 model to answer questions based on the provided context.

## ğŸš€ Features

- Fine-tuned T5 model using ~1.1 million examples from the CoQA dataset
- Context-aware question answering
- Deployed as a simple web app using Streamlit
- Fast and responsive interface
- Trained model saved and loaded from local directory

## ğŸ“ Project Structure

â”œâ”€â”€ Data
â”‚ â”œâ”€â”€ coqa-dev-v1.0.json
â”‚ â””â”€â”€ coqa-train-v1.0.json
â”œâ”€â”€ t5_coqa_final_model
â”‚ â””â”€â”€ t5_coqa_final_model
â”‚ â”œâ”€â”€ config.json
â”‚ â”œâ”€â”€ model.safetensors
â”‚ â”œâ”€â”€ tokenizer_config.json
â”‚ â””â”€â”€ ...
â”œâ”€â”€ app.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ§  Model

- **Model**: T5 (Text-to-Text Transfer Transformer)
- **Framework**: Hugging Face Transformers + PyTorch
- **Tokenizer**: SentencePiece
- **Training**: Fine-tuned for 3 epochs on a cleaned version of CoQA with early stopping and model checkpointing.

## âš™ï¸ Setup Instructions

### 1. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

2. Install dependencies

pip install -r requirements.txt

Run the Streamlit app

streamlit run app.py